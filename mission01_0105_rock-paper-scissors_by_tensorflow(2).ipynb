{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ 가위바위보 분류기 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step_0. 필요한 패키지 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL library import complete\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL library import complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step_1. train data 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> 이미지 디렉토리 경로: /home/myungjin-kim/practice/rock_scissor_paper\n",
      "가위 이미지 resize 완료!\n",
      "바위 이미지 resize 완료!\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# x_train 이미지 28x28 사이즈로 변경\n",
    "\n",
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\")+\"/practice/rock_scissor_paper\"\n",
    "print(\"=> 이미지 디렉토리 경로:\", image_dir_path)\n",
    "\n",
    "images_scissor = glob.glob(image_dir_path + \"/train_set/scissor_jpg/*.*\")\n",
    "images_rock = glob.glob(image_dir_path + \"/train_set/rock_jpg/*.*\")\n",
    "images_paper = glob.glob(image_dir_path + \"/train_set/paper_jpg/*.*\")\n",
    "\n",
    "# 파일마다 모두 28X28 사이즈로 바꾸어 저장\n",
    "target_size = (28, 28)\n",
    "\n",
    "for img in images_scissor:\n",
    "    old_img = Image.open(img)                                 # 가위 이미지를 old_img에 저장\n",
    "    new_img = old_img.resize(target_size, Image.ANTIALIAS)    # 사이즈를 재조정 해서 new_img에 저장\n",
    "    new_img.save(img,\"JPEG\")                                  # jpg와 jpeg는 같은 파일이지만 변경된 이미지를 JPEG 확장자로 통일\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "for img in images_rock:\n",
    "    old_img = Image.open(img)\n",
    "    new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "for img in images_paper:\n",
    "    old_img = Image.open(img)\n",
    "    new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 6221 입니다.\n",
      "x_train shape: (7000, 28, 28, 3)\n",
      "y_train shape: (7000,)\n"
     ]
    }
   ],
   "source": [
    "# x_train, y_train 지정 \n",
    "# y_train 라벨링\n",
    "\n",
    "def load_data(img_path):\n",
    "    \n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data = 7000  # 총 이미지 개수\n",
    "    img_size = 28\n",
    "    color = 3\n",
    "    \n",
    "    imgs = np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels = np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx = 0\n",
    "    for file in glob.iglob(img_path+'/scissor_jpg/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock_jpg/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper_jpg/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/practice/rock_scissor_paper/train_set\"\n",
    "(x_train, y_train) = load_data(image_dir_path)\n",
    "\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train의 최솟값: 0 , x_train의 최댓값: 255\n",
      "x_train_norm의 최솟값: 0.0 , x_train_norm의 최댓값: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('x_train의 최솟값:', np.min(x_train), ', x_train의 최댓값:', np.max(x_train))\n",
    "\n",
    "print('x_train_norm의 최솟값:', np.min(x_train_norm), ', x_train_norm의 최댓값:', np.max(x_train_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step_2. model 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 60,675\n",
      "Trainable params: 60,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model의 입력/출력부(가위바위보 데이터셋 Vs MNIST 데이터셋) 유의하기.\n",
    "# hyper parameter tunning\n",
    "n_channel_1 = 32\n",
    "n_channel_2 = 64\n",
    "n_channel_3 = 64\n",
    "n_dense = 64\n",
    "n_train_epoch = 20\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='sigmoid'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step_3. model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219/219 [==============================] - 3s 13ms/step - loss: 1.0009 - accuracy: 0.4234\n",
      "Epoch 2/20\n",
      "219/219 [==============================] - 3s 11ms/step - loss: 0.9019 - accuracy: 0.5254\n",
      "Epoch 3/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.6857 - accuracy: 0.6886\n",
      "Epoch 4/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.5024 - accuracy: 0.7981\n",
      "Epoch 5/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.3804 - accuracy: 0.8530\n",
      "Epoch 6/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.3184 - accuracy: 0.8759\n",
      "Epoch 7/20\n",
      "219/219 [==============================] - 3s 11ms/step - loss: 0.2553 - accuracy: 0.9010\n",
      "Epoch 8/20\n",
      "219/219 [==============================] - 3s 11ms/step - loss: 0.2143 - accuracy: 0.9160\n",
      "Epoch 9/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.1917 - accuracy: 0.9257\n",
      "Epoch 10/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.1625 - accuracy: 0.9366\n",
      "Epoch 11/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.1389 - accuracy: 0.9433\n",
      "Epoch 12/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.1267 - accuracy: 0.9489\n",
      "Epoch 13/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.1146 - accuracy: 0.9519\n",
      "Epoch 14/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0919 - accuracy: 0.9636\n",
      "Epoch 15/20\n",
      "219/219 [==============================] - 3s 11ms/step - loss: 0.0981 - accuracy: 0.9600\n",
      "Epoch 16/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0813 - accuracy: 0.9680\n",
      "Epoch 17/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0710 - accuracy: 0.9720\n",
      "Epoch 18/20\n",
      "219/219 [==============================] - 2s 11ms/step - loss: 0.0734 - accuracy: 0.9716\n",
      "Epoch 19/20\n",
      "219/219 [==============================] - 3s 11ms/step - loss: 0.0717 - accuracy: 0.9696\n",
      "Epoch 20/20\n",
      "219/219 [==============================] - 3s 12ms/step - loss: 0.0584 - accuracy: 0.9753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa1dc726b00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.compile(), model.fit()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs = n_train_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step_4. test data 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> 이미지 디렉토리 경로: /home/myungjin-kim/practice/rock_scissor_paper\n",
      "가위 이미지 resize 완료!\n",
      "바위 이미지 resize 완료!\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# x_test 이미지도 28x28 사이즈로 변경\n",
    "\n",
    "import os\n",
    "image_dir_path = os.getenv(\"HOME\")+\"/practice/rock_scissor_paper\"\n",
    "print(\"=> 이미지 디렉토리 경로:\", image_dir_path)\n",
    "\n",
    "images_scissor = glob.glob(image_dir_path + \"/test_set/scissor/*.jpg\")\n",
    "images_rock = glob.glob(image_dir_path + \"/test_set/rock/*.jpg\")\n",
    "images_paper = glob.glob(image_dir_path + \"/test_set/paper/*.jpg\")\n",
    "\n",
    "\n",
    "target_size = (28, 28)\n",
    "\n",
    "for img in images_scissor:\n",
    "    old_img = Image.open(img)\n",
    "    new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "for img in images_rock:\n",
    "    old_img = Image.open(img)\n",
    "    new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "for img in images_paper:\n",
    "    old_img = Image.open(img)\n",
    "    new_img = old_img.resize(target_size, Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "print(\"보 이미지 resize 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 611 입니다.\n",
      "x_test shape: (611, 28, 28, 3)\n",
      "y_test shape: (611,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data = 611  # 가위바위보 이미지 개수 총합\n",
    "    img_size = 28\n",
    "    color = 3\n",
    "    #이미지 데이터와 라벨(가위: 0, 바위: 1, 보: 2) 데이터를 담을 행렬 생성\n",
    "    imgs = np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels = np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx = 0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img   \n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img   \n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/practice/rock_scissor_paper/test_set\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/208.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test의 최솟값: 0 , x_test의 최댓값: 255\n",
      "x_test_norm의 최솟값: 0.0 , x_test_norm의 최댓값: 1.2259615384615385\n"
     ]
    }
   ],
   "source": [
    "print('x_test의 최솟값:', np.min(x_test), ', x_test의 최댓값:', np.max(x_test))\n",
    "\n",
    "print('x_test_norm의 최솟값:', np.min(x_test_norm), ', x_test_norm의 최댓값:', np.max(x_test_norm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step_5. test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 - 0s - loss: 2.0182 - accuracy: 0.7267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ 진행사항 ]\n",
    "\n",
    "1. 1차시도\n",
    "\n",
    "train data = 3080 (정규화 완료) / test data = 311 (정규화 완료)\n",
    "\n",
    "n_channel_1 = 32\n",
    "n_channel_2 = 64\n",
    "n_dense = 32\n",
    "n_train_epoch = 15\n",
    "\n",
    "=> result: loss: 5.9083 / accuracy: 0.6592\n",
    "\n",
    "\n",
    "2. 2차시도\n",
    "\n",
    "train data = 5020 (정규화 완료) / test data = 451 (정규화 완료)\n",
    "\n",
    "n_channel_1 = 32\n",
    "n_channel_2 = 64\n",
    "n_dense = 32\n",
    "n_train_epoch = 17\n",
    "\n",
    "=> result: loss: 5.9083 / accuracy: 0.6592\n",
    "\n",
    "2. 3차시도\n",
    "\n",
    "train data = 6221 (정규화 완료) / test data = 611 (정규화 완료)\n",
    "\n",
    "n_channel_1 = 32\n",
    "n_channel_2 = 64\n",
    "n_channel_3 = 64\n",
    "n_dense = 64\n",
    "n_train_epoch = 20\n",
    "\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='sigmoid')) # activation 함수 변경\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))                              # 추가\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))    # 추가\n",
    "\n",
    "=> result: loss: 2.0182 / accuracy: 0.7267"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ 회 고 ]\n",
    "\n",
    "1. 이번 프로젝트에서 어려웠던 점: parameter 조정이 어려움\n",
    "\n",
    "\n",
    "2. 프로젝트를 진행하면서 알아낸 점 혹은 아직 모호한 점.\n",
    "\n",
    "\n",
    "- 알아낸 점: png파일을 jpg파일로 바꾸는 방법, 분류 시스템 전반적 구축 방법, 정규화, hyperparameter조정\n",
    "\n",
    "\n",
    "- 모호한 점: train 1차 학습 후 test 1차 시도시 6.0이 넘는 accuracy가 나왔는데 train data와 test data를 늘리고 epoch와 conv2D를 증가시켜 모델을 돌렸더니 오히려 train 2차 시도시 accaracy가 1.0이 나오고 test 2차 결과는 0.5 정로 떨어졌다. 그러자 3차 시도때는 자료를 처음의 거의 두배로 늘려주고 아래 시도와 같이 하니 다시 accaracy가 7.0이 넘게 나왔다. 그런데 2차 시도시 도대체 왜 accuracy가 떨어졌는지.. 그리고 이럴때는 과적합이 맞는건지 또한 과적합을 이 모델에서 해결할 수 있는 방법은 오로지 데이터의 증가일 뿐인건지가 모호함.\n",
    "\n",
    "\n",
    "3. 루브릭 평가 지표를 맞추기 위해 시도한 것들.\n",
    "  - train_data_set과 test_data_set의 개수를 2배 가량으로 늘려줌.\n",
    "  - model의 depth를 늘려줌\n",
    "  - activation function 변경\n",
    "  - epoch 늘려줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
